{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useing Pytorch Calculating Information Entropy after MNIST Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchkeras import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEVICE] cuda\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"[DEVICE]\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_mnist(batch_size, resize=None, root='~/Datasets'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "\n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.MNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.MNIST(root=root, train=False, download=True, transform=transform)\n",
    "\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5, padding=2), # in_channels, out_channels, kernel_size\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(32, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16 * 7 * 7, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             832\n",
      "              ReLU-2           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 14, 14]           4,624\n",
      "              ReLU-5           [-1, 16, 14, 14]               0\n",
      "         MaxPool2d-6             [-1, 16, 7, 7]               0\n",
      "            Linear-7                   [-1, 10]           7,850\n",
      "           Sigmoid-8                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 13,306\n",
      "Trainable params: 13,306\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.002991\n",
      "Forward/backward pass size (MB): 0.484650\n",
      "Params size (MB): 0.050758\n",
      "Estimated Total Size (MB): 0.538399\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "summary(net, input_shape=(1, img_rows, img_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定 device 就使用 net 的 device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭 dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 不考虑 GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有 is_training 这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 1.6784, train acc 0.816, test acc 0.917, time 1.9 sec\n",
      "epoch 2, loss 1.5376, train acc 0.932, test acc 0.952, time 1.9 sec\n",
      "epoch 3, loss 1.5107, train acc 0.956, test acc 0.966, time 1.8 sec\n",
      "epoch 4, loss 1.4996, train acc 0.967, test acc 0.973, time 1.8 sec\n",
      "epoch 5, loss 1.4938, train acc 0.972, test acc 0.976, time 1.8 sec\n",
      "epoch 6, loss 1.4899, train acc 0.975, test acc 0.976, time 1.7 sec\n",
      "epoch 7, loss 1.4869, train acc 0.978, test acc 0.980, time 1.7 sec\n",
      "epoch 8, loss 1.4843, train acc 0.980, test acc 0.982, time 1.8 sec\n",
      "epoch 9, loss 1.4832, train acc 0.981, test acc 0.981, time 1.7 sec\n",
      "epoch 10, loss 1.4814, train acc 0.982, test acc 0.984, time 1.9 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 10\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(net.parameters())    # lr is not required\n",
    "train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy in the test set of 10,000-pictures was: 98.36%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in test_iter:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "print(\n",
    "    \"The accuracy in the test set of 10,000-pictures was: {:.2f}%\".format(\n",
    "        correct.cpu().numpy() / total * 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(os.path.abspath('.'), \"models\")\n",
    "model_name = \"lenet1.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] lenet1.pth Model File is Successfully Saved!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "    # If models directory does not exist, create a directory\n",
    "    os.makedirs(model_dir) \n",
    "    print(\"[INFO]\", model_dir, \"is Successfully Created!\")\n",
    "\n",
    "torch.save(net.state_dict(), os.path.join(model_dir, model_name))\n",
    "print(\"[INFO]\", model_name, \"Model File is Successfully Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priority Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] lenet1.pth Model File is Successfully Loaded!\n"
     ]
    }
   ],
   "source": [
    "pretrained_net = torch.load(os.path.join(model_dir, model_name))\n",
    "load_net = LeNet()\n",
    "load_net.load_state_dict(pretrained_net)\n",
    "print(\"[INFO]\", model_name, \"Model File is Successfully Loaded!\")\n",
    "# del net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             832\n",
      "              ReLU-2           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 14, 14]           4,624\n",
      "              ReLU-5           [-1, 16, 14, 14]               0\n",
      "         MaxPool2d-6             [-1, 16, 7, 7]               0\n",
      "            Linear-7                   [-1, 10]           7,850\n",
      "           Sigmoid-8                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 13,306\n",
      "Trainable params: 13,306\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.002991\n",
      "Forward/backward pass size (MB): 0.484650\n",
      "Params size (MB): 0.050758\n",
      "Estimated Total Size (MB): 0.538399\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(load_net, input_shape=(1, img_rows, img_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Priority Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = tuple(range(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xi_score(idx, model, n_class=10):\n",
    "    \n",
    "    dataiter = iter(test_iter)        # 把测试数据放在迭代器 iter\n",
    "    images, labels = dataiter.next()\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    plot_image = images[idx].cpu().numpy().reshape(img_rows, img_cols)\n",
    "    x_input = images[idx].reshape(-1, 1, img_rows, img_cols).cpu()\n",
    "    outputs = model(x_input)\n",
    "    predict_list = model(x_input).cpu().detach().numpy()\n",
    "    predict_label = np.argmax(predict_list, axis=-1)\n",
    "\n",
    "    x_score = - np.inner(\n",
    "        predict_list[0],\n",
    "        np.divide(np.log(predict_list)[0], np.log(n_class))\n",
    "    )\n",
    "\n",
    "    return predict_list[0], predict_label, x_score, classes[labels[idx]], plot_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Print Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_onehot(labels_dense, n_classes=10):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_onehot = np.zeros((num_labels,num_classes))\n",
    "    labels_onehot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xi_print(p_lst, p_class, r_class, score):\n",
    "\n",
    "    col_name = [\"Label\", \"Predict_Probability\", \"FCT\"]\n",
    "    col_len = [len(item) for item in col_name]\n",
    "    total_len = sum(col_len) + 3 * len(col_len) - 1\n",
    "\n",
    "    title = \"Predict Table\"\n",
    "\n",
    "    print(title.center(len(title) + 2).center(total_len, \"=\"))\n",
    "    print('_' * total_len)\n",
    "    print(\n",
    "        \"\", col_name[0], \n",
    "        \"|\", col_name[1], \n",
    "        \"|\", col_name[2], \"\"\n",
    "    )\n",
    "    print(\n",
    "        \"\", \"-\" * col_len[0], \n",
    "        \"|\", \"-\" * col_len[1], \n",
    "        \"|\", \"-\" * col_len[2], \"\"\n",
    "    )\n",
    "\n",
    "#     pred_one_hot = np_utils.to_categorical(p_class, num_classes)\n",
    "    pred_one_hot = dense_to_onehot(p_class, num_classes)[0]\n",
    "\n",
    "    for idx, item in zip(range(len(p_lst)), p_lst):\n",
    "        print(\n",
    "            \"\", str(idx).center(col_len[0]), \"|\", \n",
    "            \"%.6e\".rjust(col_len[1] - 8) % item, \"|\", \n",
    "            str(\"*\" * int(pred_one_hot[idx])).center(col_len[2]), \"\"\n",
    "        )\n",
    "\n",
    "    print('=' * total_len)\n",
    "    print(\" Realistic Class :\", r_class)\n",
    "    print(\" Predict Class   :\", p_class[0])\n",
    "    print(\" Predict Validity:\", p_class[0] == r_class)\n",
    "    print(\" Priority Score  :\", score)\n",
    "    print('_' * total_len)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 152\n",
      "========== Predict Table ==========\n",
      "___________________________________\n",
      " Label | Predict_Probability | FCT \n",
      " ----- | ------------------- | --- \n",
      "   0   |        1.431841e-08 |     \n",
      "   1   |        1.677064e-21 |     \n",
      "   2   |        1.967118e-14 |     \n",
      "   3   |        8.241845e-19 |     \n",
      "   4   |        7.055617e-13 |     \n",
      "   5   |        1.000000e+00 |  *  \n",
      "   6   |        9.484194e-14 |     \n",
      "   7   |        2.738430e-12 |     \n",
      "   8   |        6.247323e-07 |     \n",
      "   9   |        5.573767e-11 |     \n",
      "===================================\n",
      " Realistic Class : 5\n",
      " Predict Class   : 5\n",
      " Predict Validity: True\n",
      " Priority Score  : 3.9889583e-06\n",
      "___________________________________\n"
     ]
    }
   ],
   "source": [
    "# For example\n",
    "index = np.random.choice(range(batch_size))\n",
    "print(\"Index:\", index)\n",
    "p_list, p_label, x_score, r_label, _ = xi_score(index, load_net, num_classes)\n",
    "output = xi_print(p_list, p_label, r_label, x_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Eg.001] Index.0176:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEDElEQVR4nO3dsS5taxSA0buEXnVKhUqhUSmUKp7Lk0g0eoVGzwNItEhEIUSpsO4LsI4be9vfvsYo94xkJiefmZw/GMZx/AfoWVn0AsDHxAlR4oQocUKUOCFqdWo4DIP/yoU5G8dx+OhzlxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBA1+ScAWT7n5+eT85OTk8n58fHxLNfhG1xOiBInRIkTosQJUeKEKHFClDghyjvnkllZmf5+enV1NTm/vLyc5TrMkcsJUeKEKHFClDghSpwQJU6IEidEDeM4fj4chs+HLMTBwcHk/OzsbHK+vb09Ob++vv7PO/E94zgOH33uckKUOCFKnBAlTogSJ0SJE6L8yNiSeX9//9bXHx4eTs49pXS4nBAlTogSJ0SJE6LECVHihChxQpR3zl/m+fl50SvwRS4nRIkTosQJUeKEKHFClDghSpwQ5Z1zyezu7n7r6//8+TOjTZg3lxOixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiPLznL/MxcXFolfgi1xOiBInRIkTosQJUeKEKHFClKeUX+bp6WnRK/BFLidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQ5ffWLpn19fXJ+c3NzeT89vZ2htswTy4nRIkTosQJUeKEKHFClDghSpwQ5Z1zyezv70/OHx4eJudvb2+zXIc5cjkhSpwQJU6IEidEiROixAlRnlJiNjc3J+dbW1uT86Ojo1muwwK5nBAlTogSJ0SJE6LECVHihChxQpR3zpjV1el/krW1tR/ahEVzOSFKnBAlTogSJ0SJE6LECVHihCjvnDF/+9WWd3d3P7QJi+ZyQpQ4IUqcECVOiBInRIkTosQJUd45Y3Z2dibnGxsbk/PHx8dZrsMCuZwQJU6IEidEiROixAlR4oQoTykxe3t7k/P7+/vJ+enp6SzXYYFcTogSJ0SJE6LECVHihChxQpQ4Ico755J5fX2dnL+8vPzMIsydywlR4oQocUKUOCFKnBAlTogSJ0R551wyf/t5Tv4/XE6IEidEiROixAlR4oQocUKUOCFqGMfx8+EwfD4EZmIcx+Gjz11OiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFC1OSfAAQWx+WEKHFClDghSpwQJU6IEidE/QtcKV60dqvHNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Predict Table ==========\n",
      "___________________________________\n",
      " Label | Predict_Probability | FCT \n",
      " ----- | ------------------- | --- \n",
      "   0   |        2.373806e-05 |     \n",
      "   1   |        9.999980e-01 |  *  \n",
      "   2   |        7.279323e-05 |     \n",
      "   3   |        1.297069e-05 |     \n",
      "   4   |        4.293202e-04 |     \n",
      "   5   |        8.630037e-04 |     \n",
      "   6   |        3.809989e-04 |     \n",
      "   7   |        6.873820e-04 |     \n",
      "   8   |        7.114615e-04 |     \n",
      "   9   |        1.270086e-07 |     \n",
      "===================================\n",
      " Realistic Class : 1\n",
      " Predict Class   : 1\n",
      " Predict Validity: True\n",
      " Priority Score  : 0.010282272\n",
      "___________________________________\n",
      "\n",
      "Quit for the Example? yes/[No]: y\n"
     ]
    }
   ],
   "source": [
    "key_in = \"\"\n",
    "seed = 0\n",
    "quit_input = [\"y\", \"yes\"]\n",
    "while key_in.lower() not in quit_input:\n",
    "    seed += 1\n",
    "#     np.random.seed(seed)\n",
    "    index = np.random.choice(range(batch_size))\n",
    "    print(\n",
    "        \"\\n[Eg.\" + str(seed).rjust(3, \"0\") + \\\n",
    "        \"] Index.\" + str(index).rjust(4, \"0\") + \":\"\n",
    "    )\n",
    "    \n",
    "    p_list, p_label, x_score, r_label, plot_image = xi_score(index, load_net, num_classes)\n",
    "    \n",
    "    # Numerical Data Visualization\n",
    "    im = plt.imshow(plot_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    output = xi_print(p_list, p_label, r_label, x_score)\n",
    "\n",
    "    if output:\n",
    "        time.sleep(1)\n",
    "        key_in = input(\"\\nQuit for the Example? yes/[No]: \")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
